//Parser generated by rustlr for grammar verilog

#![allow(unused_variables)]
#![allow(non_snake_case)]
#![allow(non_camel_case_types)]
#![allow(unused_parens)]
#![allow(unused_mut)]
#![allow(unused_imports)]
#![allow(unused_assignments)]
#![allow(dead_code)]
#![allow(irrefutable_let_patterns)]
#![allow(unreachable_patterns)]
extern crate rustlr;
use rustlr::{Tokenizer,TerminalToken,ZCParser,ZCRProduction,Stateaction,decode_action};
use rustlr::{StrTokenizer,RawToken,LexSource};
use std::collections::{HashMap,HashSet};
use crate::absyntax::*;
use crate::absyntax::Construct::*;
use crate::absyntax::Direction::*;
use rustlr::{LBox, makelbox};

static SYMBOLS:[&'static str;23] = ["ID","#","(",")",",",";","LBR","RBR","module","endmodule","input","output","wire","xor","and","or","Module","ModuleNonAnsiHeader","ListOfPorts","ListOfPortsTail","Port","START","EOF"];

static TABLE:[u64;26] = [73014640641,34359803904,68719607809,281474976972800,563044442701827,844463585165312,1125977216647169,1125908497235968,1407469372833794,1688871335624704,1970324837629952,1970410736910337,2251838468456450,2533291971051520,2533287675494402,2533356395495425,2814766947303426,2814762652336130,3096237629571072,3377699721183232,3377785620791297,3659196172206082,3940666854604800,3940662559047682,3940731279310849,4222137535823874,];

pub fn make_parser<'src_lt>() -> ZCParser<Construct<'src_lt>,Construct<'src_lt>>
{
 let mut parser1:ZCParser<Construct<'src_lt>,Construct<'src_lt>> = ZCParser::new(7,16);
 let mut rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("start");
 rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("Module");
 rule.Ruleaction = |parser|{ let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Header(h),)=(_item0_.value,) { 
    Module(ModuleDec{ name:h.name,
                      ports:h.ports })
    }  else {parser.bad_pattern("(Header(h),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("ModuleNonAnsiHeader");
 rule.Ruleaction = |parser|{ let mut _item3_ = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Ports(p),Id(i),)=(_item2_.value,_item1_.value,) { 
    Header(HeaderDec{ name:i,
                      ports:p, })
    }  else {parser.bad_pattern("(Ports(p),Id(i),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("ListOfPorts");
 rule.Ruleaction = |parser|{ let mut _item3_ = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Ports(mut l),Port(p),)=(_item2_.value,_item1_.value,) { 
    l.push(parser.lb(p));
    Ports(l)
    }  else {parser.bad_pattern("(Ports(mut l),Port(p),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("ListOfPortsTail");
 rule.Ruleaction = |parser|{  Ports(Vec::new()) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("ListOfPortsTail");
 rule.Ruleaction = |parser|{ let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Ports(mut l),Port(p),)=(_item2_.value,_item1_.value,) { 
    l.push(parser.lb(p));
    Ports(l)
    }  else {parser.bad_pattern("(Ports(mut l),Port(p),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("Port");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let (Id(i),)=(_item0_.value,) { 
    Port(PortDec{ name:i,
                   direction: Direction::Unspecified})
    }  else {parser.bad_pattern("(Id(i),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Construct<'src_lt>,Construct<'src_lt>>::new_skeleton("START");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Construct<'src_lt>>::default()};
 parser1.Rules.push(rule);
 parser1.Errsym = "";

 for i in 0..26 {
   let symi = ((TABLE[i] & 0x0000ffff00000000) >> 32) as usize;
   let sti = ((TABLE[i] & 0xffff000000000000) >> 48) as usize;
   parser1.RSM[sti].insert(SYMBOLS[symi],decode_action(TABLE[i]));
 }

 for s in SYMBOLS { parser1.Symset.insert(s); }

 load_extras(&mut parser1);
 return parser1;
} //make_parser


// Lexical Scanner using RawToken and StrTokenizer
pub struct veriloglexer<'t> {
   stk: StrTokenizer<'t>,
   keywords: HashSet<&'static str>,
}
impl<'t> veriloglexer<'t> 
{
  pub fn from_str(s:&'t str) -> veriloglexer<'t>  {
    Self::new(StrTokenizer::from_str(s))
  }
  pub fn from_source(s:&'t LexSource<'t>) -> veriloglexer<'t>  {
    Self::new(StrTokenizer::from_source(s))
  }
  pub fn new(mut stk:StrTokenizer<'t>) -> veriloglexer<'t> {
    let mut keywords = HashSet::with_capacity(16);
    for kw in ["module","endmodule","input","output","wire","xor","and","or",] {keywords.insert(kw);}
    for c in ['#','(',')',',',';','{','}',] {stk.add_single(c);}
    for d in [] {stk.add_double(d);}
    veriloglexer {stk,keywords}
  }
}
impl<'src_lt> Tokenizer<'src_lt,Construct<'src_lt>> for veriloglexer<'src_lt>
{
   fn nextsym(&mut self) -> Option<TerminalToken<'src_lt,Construct<'src_lt>>> {
    let tokopt = self.stk.next_token();
    if let None = tokopt {return None;}
    let token = tokopt.unwrap();
    match token.0 {
      RawToken::Alphanum(sym) if self.keywords.contains(sym) => Some(TerminalToken::from_raw(token,sym,<Construct<'src_lt>>::default())),
      RawToken::Alphanum(x) => Some(TerminalToken::from_raw(token,"ID",Id(x))),
      RawToken::Symbol(r"{") => Some(TerminalToken::from_raw(token,"LBR",<Construct<'src_lt>>::default())),
      RawToken::Symbol(r"}") => Some(TerminalToken::from_raw(token,"RBR",<Construct<'src_lt>>::default())),
      RawToken::Symbol(s) => Some(TerminalToken::from_raw(token,s,<Construct<'src_lt>>::default())),
      RawToken::Alphanum(s) => Some(TerminalToken::from_raw(token,s,<Construct<'src_lt>>::default())),
      _ => Some(TerminalToken::from_raw(token,"<LexicalError>",<Construct<'src_lt>>::default())),
    }
  }
   fn linenum(&self) -> usize {self.stk.line()}
   fn column(&self) -> usize {self.stk.column()}
   fn position(&self) -> usize {self.stk.current_position()}
}//impl Tokenizer

fn load_extras<'src_lt>(parser:&mut ZCParser<Construct<'src_lt>,Construct<'src_lt>>)
{
}//end of load_extras: don't change this line as it affects augmentation
